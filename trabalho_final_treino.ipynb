{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH77WfFd3hLaTaRanPyUa/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorgrrtj/trabalho_final_puc/blob/main/trabalho_final_treino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T9_JTLXrKYN"
      },
      "source": [
        "\n",
        "# Trabalho Final - Treinamento do Modelo Preditivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fqYjJjrasB"
      },
      "source": [
        "## Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aWsgUxLRRwk"
      },
      "source": [
        "# Importação das bibliotecas\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from IPython.display import HTML\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import joblib\n",
        "headers = {\n",
        "    'Authorization': 'Bearer $ACCESS_TOKEN',\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQU3oTeEtZxC"
      },
      "source": [
        "## Sumarização de todas as extrações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8PdWveGW6XS"
      },
      "source": [
        "\"\"\" Contém looping para todas as páginas.\n",
        "Retorna um dicionário com as informações de cada imóvel.\n",
        "Devido à quantidade de páginas, este processo pode demorar mais de 30 minutos.\"\"\"\n",
        "\n",
        "headers = {\n",
        "    'Authorization': 'Bearer $ACCESS_TOKEN',\n",
        "}\n",
        "\n",
        "offset = 0\n",
        "pag_inicial = 'https://api.mercadolibre.com/sites/MLB/search?q=Iphone%2014&offset='+str(offset)\n",
        "\n",
        "response = requests.get(\n",
        "  pag_inicial,\n",
        "  headers=headers)\n",
        "json = response.json()\n",
        "qtd_pag = round(json['paging']['total']/50)\n",
        "qtd_itens = json['paging']['total']\n",
        "\n",
        "print(\"Foram encontradas {} páginas e {} produtos.\".format(qtd_pag, qtd_itens))\n",
        "\n",
        "offset = 0\n",
        "url_list = [pag_inicial]\n",
        "for page in range(qtd_pag):\n",
        "  offset += 50\n",
        "  prox_pagina = 'https://api.mercadolibre.com/sites/MLB/search?q=Iphone%2014&offset='+str(offset)\n",
        "  url_list.append(prox_pagina)\n",
        "\n",
        "extracted_data = []\n",
        "\n",
        "for index, url in enumerate(url_list):\n",
        "  response = requests.get(\n",
        "      url,\n",
        "      headers=headers)\n",
        "  print(\"Codigo de resposta da pagina {}: {}\".format(url, response.status_code))\n",
        "\n",
        "  json = response.json()\n",
        "  results = json['results']\n",
        "  time.sleep(random.randint(2,6))\n",
        "\n",
        "  for item in results:\n",
        "    product_dict = {}\n",
        "    product_dict['id'] = item.get('id')\n",
        "    product_dict['titulo'] = item.get('title')\n",
        "    product_dict['condicao'] = item.get('condition')\n",
        "    product_dict['link'] = item.get('permalink')\n",
        "    product_dict['preco'] = item.get('price')\n",
        "    for attribute in item.get('attributes'):\n",
        "      if attribute.get('name') == 'Marca':\n",
        "        product_dict['marca'] = attribute.get('value_name')\n",
        "      elif attribute.get('name') == 'Linha':\n",
        "        product_dict['linha'] = attribute.get('value_name')\n",
        "      elif attribute.get('name') == 'Modelo':\n",
        "        product_dict['modelo'] = attribute.get('value_name')\n",
        "    product_dict['nome_vendedor'] = item.get('seller').get('nickname')\n",
        "    product_dict['nvl_vendedor'] = item.get('seller').get('seller_reputation').get('level_id')\n",
        "    product_dict['vendas_concluidas'] = item.get('seller').get('seller_reputation').get('transactions').get('completed')\n",
        "    product_dict['qtd_avaliacoes'] = item.get('seller').get('seller_reputation').get('transactions').get('total')\n",
        "    product_dict['avlc_pos'] = item.get('seller').get('seller_reputation').get('transactions').get('ratings').get('positive')\n",
        "    product_dict['avlc_neut'] = item.get('seller').get('seller_reputation').get('transactions').get('ratings').get('neutral')\n",
        "    product_dict['avlc_neg'] = item.get('seller').get('seller_reputation').get('transactions').get('ratings').get('negative')\n",
        "    extracted_data.append(product_dict)\n",
        "\n",
        "  print('Finished page ' + str(index + 1))\n",
        "print('Finished all pages')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.json_normalize(extracted_data)"
      ],
      "metadata": {
        "id": "HUk1MkcB9UNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"modelo\"].unique()"
      ],
      "metadata": {
        "id": "njoJWYcqWoF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['modelo'] = df['modelo'].str.replace('IPHONE', 'iPhone')\n",
        "df['modelo'] = df['modelo'].str.replace('iphone', 'iPhone')\n",
        "df['modelo'] = df['modelo'].str.replace('Iphone', 'iPhone')"
      ],
      "metadata": {
        "id": "0rNbHOra9vjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.index[df['modelo'] == 'iPhone'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 7'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 7 Plus'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 12 Pro'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhones 8 ao 14'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 11'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 11 Pro'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 11 Pro Max'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 13'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 13 Pro'], inplace=True)\n",
        "df.drop(df.index[df['modelo'] == 'iPhone 13 Pro Max'], inplace=True)\n",
        "df.drop(df.index[df['titulo'].str.contains('iphone', case=False) == False], inplace=True)\n",
        "df.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "pj0NQFYGZov7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[\"modelo\"] == \"14 PRO MAX\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 PRO MAX 128GB\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 Pro 256gb\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 PRO ROXO PROFUNDO 128GB\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"14 PRO\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14Pro Max 1TB\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"Sem Rádio\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"14 Pro Max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14Pro Tela de 6,1 polegadas¹\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone Pro Max 256GB\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 Pro Max Original\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"A2894\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"MPX33BE/A\", \"modelo\"] = 'iPhone 14'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 PRO\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 PRO MAX\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 pro max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 pro max128\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 Pro\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14pro max 256gb\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"IPhone 14 Pro Max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 pro maxx\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 128 gb\", \"modelo\"] = 'iPhone 14'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 11 Pro Max\", \"modelo\"] = 'iPhone 11 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 pro Max 128gb\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 por max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 PRO MAX ROXO PROFUNDO 128GB\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"A2650\", \"modelo\"] = 'iPhone 14 Pro'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 128gb\", \"modelo\"] = 'iPhone 14'\n",
        "df.loc[df[\"modelo\"] == \"MQ503BE/A\", \"modelo\"] = 'iPhone 14 Plus'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 BR\", \"modelo\"] = 'iPhone 14'\n",
        "df.loc[df[\"modelo\"] == \"14\", \"modelo\"] = 'iPhone 14'\n",
        "df.loc[df[\"modelo\"] == \"14 Pro Max 256gb\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 pro max 256gb\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 pro Max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 Pro Max - NOVO sem a caixa\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14 pro Max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 Pro Max 256\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"iPhone 14s Pro Max\", \"modelo\"] = 'iPhone 14 Pro Max'\n",
        "df.loc[df[\"modelo\"] == \"14 pro max\", \"modelo\"] = 'iPhone 14 Pro Max'"
      ],
      "metadata": {
        "id": "eahSm_bgcRmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del_index = df[(df['modelo'] == 'iPhone 14 Pro Max') & (df['titulo'].str.contains('max', case=False) == False)].index\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro Max') & (df['titulo'].str.contains('plus', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro Max') & (df['titulo'].str.contains('iphone 14', case=False) == False)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro') & (df['titulo'].str.contains('pro', case=False) == False)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro') & (df['titulo'].str.contains('max', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro') & (df['titulo'].str.contains('plus', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14 Pro') & (df['titulo'].str.contains('iphone 14', case=False) == False)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14') & (df['titulo'].str.contains('pro', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14') & (df['titulo'].str.contains('max', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14') & (df['titulo'].str.contains('plus', case=False) == True)].index)\n",
        "del_index = del_index.append(df[(df['modelo'] == 'iPhone 14') & (df['titulo'].str.contains('iphone 14', case=False) == False)].index)\n",
        "del_index = del_index.append(df[df['titulo'].str.contains('iphone', case=False) == False].index)\n",
        "del_index = del_index.append(df[df['titulo'].str.contains('14', case=False) == False].index)"
      ],
      "metadata": {
        "id": "XA4hcaT5497Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(del_index).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GnYapYqH66vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base = df[['titulo', 'modelo']]"
      ],
      "metadata": {
        "id": "n_gzLqlUgNvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separação do label e das features\n",
        "X = df_base.drop('modelo', axis=1).values\n",
        "y = df_base['modelo'].values\n",
        "\n",
        "# Separação de dados de treino e teste\n",
        "train_features, test_features, class_train, class_test = train_test_split(X, y, test_size=0.20, random_state=10, stratify=y)"
      ],
      "metadata": {
        "id": "R1r-xHG6zCBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Criação de matriz com a contagem de cada token SEM stop words\n",
        "cv = CountVectorizer(max_features=1000)\n",
        "cv_train_features = cv.fit_transform(train_features.ravel())\n",
        "cv_test_features = cv.transform(test_features.ravel())\n",
        "\n",
        "print('Shape das features de treino:', cv_train_features.shape, ' Shape das features de teste:', cv_test_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2_WhHqh9rfP",
        "outputId": "bc13c4cb-7c72-460c-fea2-f3468bf34994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape das features de treino: (495, 206)  Shape das features de teste: (124, 206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def train_predict_model(classifier, \n",
        "                        train_features, train_labels, \n",
        "                        test_features, test_labels):\n",
        "    classifier = classifier.fit(train_features, train_labels)\n",
        "    predictions = classifier.predict(test_features) \n",
        "    return predictions "
      ],
      "metadata": {
        "id": "V0hv9eeF9wPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    total_classes = len(classes)\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
        "\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "\n",
        "    cm_frame = pd.DataFrame(cm, index=classes, columns=classes,)\n",
        "    cm_frame.index.name = 'Actual'\n",
        "    cm_frame.columns.name = 'Predicted'\n",
        "\n",
        "    print(cm_frame)\n",
        "\n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
        "\n",
        "    report = metrics.classification_report(y_true=true_labels, \n",
        "                                           y_pred=predicted_labels, \n",
        "                                           labels=classes) \n",
        "    print(report)\n",
        "\n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
        "    print('Model Performance metrics:')\n",
        "    print('-'*30)\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
        "    print('\\nModel Classification report:')\n",
        "    print('-'*30)\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                                  classes=classes)\n",
        "    print('\\nPrediction Confusion Matrix:')\n",
        "    print('-'*30)\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                             classes=classes)\n",
        "    \n",
        "def get_metrics(true_labels, predicted_labels):\n",
        "    \n",
        "    print('Accuracy:', np.round(\n",
        "                        metrics.accuracy_score(true_labels, \n",
        "                                               predicted_labels),\n",
        "                        4))\n",
        "    print('Precision:', np.round(\n",
        "                        metrics.precision_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('Recall:', np.round(\n",
        "                        metrics.recall_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('F1 Score:', np.round(\n",
        "                        metrics.f1_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n"
      ],
      "metadata": {
        "id": "gJ9o329M90PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "rfc = RandomForestClassifier(n_jobs=-1)\n",
        "\n",
        "classes = list(df_base['modelo'].unique())\n",
        "\n",
        "classifier = rfc.fit(cv_train_features, class_train)\n",
        "\n",
        "rfc_tfidf_predictions = train_predict_model(classifier=rfc, \n",
        "                                                train_features=cv_train_features, train_labels=class_train,\n",
        "                                                test_features=cv_test_features, test_labels=class_test)\n",
        "\n",
        "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=classes)"
      ],
      "metadata": {
        "id": "QeNrLnAq91aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(classifier, \"model.joblib\")\n",
        "joblib.dump(cv, \"cv.joblib\")"
      ],
      "metadata": {
        "id": "P4fzKNO9-mOU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}